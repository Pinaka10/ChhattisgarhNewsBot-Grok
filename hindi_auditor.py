# Chhattisgarh News Auditor
# Audits news for professional Hindi standards with sentiment/bias detection

import re
import os
import time
from indicnlp.tokenize import sentence_tokenize
from indicnlp.sentiment import SentimentAnalyzer

# Create logs directory if it doesn't exist
os.makedirs('logs', exist_ok=True)

# Setup logging
with open('logs/auditor.log', 'a') as log_file:
    log_file.write(f"{time.ctime()} - Auditor started\n")

# Professional replacements and removal list
REPLACEMENTS = {
    "рдпрд╛рд░": "рдорд┐рддреНрд░", "рднрд╛рдИ": "рд╡реНрдпрдХреНрддрд┐", "рдЕрд░реЗ": "", "рд╡рд╛рд╣": "", "рдЬрдмрд░рджрд╕реНрдд": "рдорд╣рддреНрд╡рдкреВрд░реНрдг",
    "рдХрдорд╛рд▓": "рдЙрд▓реНрд▓реЗрдЦрдиреАрдп", "рдзрдорд╛рдХрд╛": "рдШрдЯрдирд╛", "рдмрд╡рд╛рд▓": "рд╡рд┐рд╡рд╛рдж", "рдлрдЯрд╛рдлрдЯ": "рддреБрд░рдВрдд",
    "рдЭрдЯрдкрдЯ": "рд╢реАрдШреНрд░", "рд╢ocking": "рдЪрд┐рдВрддрд╛рдЬрдирдХ", "awesome": "рдорд╣рддреНрд╡рдкреВрд░реНрдг",
    "amazing": "рдЖрд╢реНрдЪрд░реНрдпрдЬрдирдХ", "fantastic": "рдЙрддреНрдХреГрд╖реНрдЯ", "super": "рдЕрддреНрдпрдзрд┐рдХ",
    "cool": "рдЕрдЪреНрдЫрд╛", "wow": "", "ok": "рдареАрдХ", "sorry": "рдЦреЗрдж", "thanks": "рдзрдиреНрдпрд╡рд╛рдж",
    "рдорд╛рд░": "рд╣рдорд▓рд╛", "рдкреАрдЯ": "рдкреНрд░рд╣рд╛рд░", "рдлрдВрд╕рд╛": "рдЧрд┐рд░рдлреНрддрд╛рд░", "рдкрдХрдбрд╝рд╛": "рдЧрд┐рд░рдлреНрддрд╛рд░",
    "рднрд╛рдЧрд╛": "рдлрд░рд╛рд░", "рдЫреБрдкрд╛": "рдЕрдЬреНрдЮрд╛рдд рд╕реНрдерд╛рди рдкрд░", "рд╕рдирд╕рдиреАрдЦреЗрдЬ": "рдорд╣рддреНрд╡рдкреВрд░реНрдг",
    "рд╣реИрд░рд╛рди": "рдЖрд╢реНрдЪрд░реНрдпрдЪрдХрд┐рдд", "рдкрд░реЗрд╢рд╛рди": "рдЪрд┐рдВрддрд┐рдд", "рдЧреБрд╕реНрд╕рд╛": "рдирд╛рд░рд╛рдЬрд╝", "рдЦреБрд╢": "рдкреНрд░рд╕рдиреНрди"
}
REMOVE_WORDS = ["рдЕрд░реЗ", "рд╡рд╛рд╣", "рд╣рд╛рдп", "рдУрд╣", "рдЖрд╣", "рдЙрдлреНрдл", "рдЫреА", "рдереВ", "wow", "omg", "wtf", "damn", "shit", "fuck", "hell"]

# Initialize sentiment analyzer
analyzer = SentimentAnalyzer()

def clean_text(text):
    if not text:
        return text
    text = str(text)
    text = re.sub(r'\s+', ' ', text).strip()
    for old_word, new_word in REPLACEMENTS.items():
        text = re.sub(re.escape(old_word), new_word, text, flags=re.IGNORECASE)
    for word in REMOVE_WORDS:
        text = re.sub(r'\b' + re.escape(word) + r'\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text).strip()
    if text and text[0].islower():
        text = text[0].upper() + text[1:]
    if text and text[-1] not in 'ред.!?':
        text = text + 'ред'
    return text

def categorize_news(title):
    title_lower = title.lower()
    categories = {
        "crime": ["рдкреБрд▓рд┐рд╕", "рдЧрд┐рд░рдлреНрддрд╛рд░", "рдЪреЛрд░реА", "рд╣рддреНрдпрд╛", "рдЕрдкрд░рд╛рдз", "рдорд╛рдорд▓рд╛", "рдлреНрд░реЙрдб"],
        "politics": ["рдореБрдЦреНрдпрдордВрддреНрд░реА", "рдордВрддреНрд░реА", "рд╡рд┐рдзрд╛рдпрдХ", "рдЪреБрдирд╛рд╡", "рд╕рд░рдХрд╛рд░", "рдиреЗрддрд╛"],
        "development": ["рд╡рд┐рдХрд╛рд╕", "рдпреЛрдЬрдирд╛", "рдкрд░рд┐рдпреЛрдЬрдирд╛", "рдирд┐рд░реНрдорд╛рдг", "рдЙрджреНрдШрд╛рдЯрди"]
    }
    for cat, keywords in categories.items():
        if any(keyword in title_lower for keyword in keywords):
            return {"category": cat, "emoji": {"crime": "ЁЯЪи", "politics": "ЁЯУМ", "development": "ЁЯПЧя╕П"}.get(cat, "ЁЯУ░")}
    return {"category": "general", "emoji": "ЁЯУ░"}

def audit_sentiment(item):
    sentences = sentence_tokenize.sentence_split(item["headline"], lang="hi")
    sentiment = analyzer.get_sentiment(sentences)
    if sentiment["compound"] < -0.8:  # Highly negative sentiment
        with open('logs/auditor.log', 'a') as log_file:
            log_file.write(f"{time.ctime()} - Rejected {item['headline']} due to high negativity\n")
        return False
    return True

def audit_news(items):
    verified = []
    for item in items:
        cleaned_text = clean_text(item["headline"])
        if not cleaned_text:
            continue
        category_info = categorize_news(cleaned_text)
        if audit_sentiment({"headline": cleaned_text}):
            item["headline"] = f"{category_info['emoji']} {cleaned_text}"
            item["category"] = category_info["category"]
            item["audit_timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
            verified.append(item)
        with open('logs/auditor.log', 'a') as log_file:
            log_file.write(f"{time.ctime()} - Audited {item['headline']} as {category_info['category']}\n")
    return verified

if __name__ == "__main__":
    # Example usage with test data
    test_items = [{"headline": "рдЬрдмрд░рджрд╕реНрдд рдмрд╛рд░рд┐рд╢ рдиреЗ рд░рд╛рдпрдкреБрд░ рдХреЛ рдкреНрд░рднрд╛рд╡рд┐рдд рдХрд┐рдпрд╛", "source": "Test", "date": time.strftime("%Y-%m-%d")}]
    audited_items = audit_news(test_items)
    with open('data/audited_news.json', 'w', encoding='utf-8') as f:
        json.dump(audited_items, f, ensure_ascii=False, indent=2)
